{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lesson 3: Numpy and Pandas for 2D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2342.5999999999999, 3239.9000000000001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership[1, 3]\n",
    "    print ridership[1:3, 3:5]\n",
    "    print ridership[1, :]\n",
    "    \n",
    "# Vectorized operations on rows or columns\n",
    "if False:\n",
    "    print ridership[0, :] + ridership[1, :]\n",
    "    print ridership[:, 0] + ridership[:, 1]\n",
    "    \n",
    "# Vectorized operations on entire arrays\n",
    "if False:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print a + b\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    ## Find the station with the maximum riders on the first day\n",
    "    max_station = ridership[0, :].argmax()\n",
    "    \n",
    "    ## Find the mean riders per day for that station\n",
    "    mean_for_max = ridership[:, max_station].mean()\n",
    "    \n",
    "    ## Find the mean ridership overall for comparison\n",
    "    overall_mean = ridership[:, :].mean()\n",
    "    # or easier to write ridership.mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3239.9000000000001, 1071.2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# NumPy axis argument\n",
    "if False:\n",
    "    a = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ])\n",
    "    \n",
    "    print a.sum()\n",
    "    print a.sum(axis=0)\n",
    "    print a.sum(axis=1)\n",
    "    \n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    mean_ridership = ridership.mean(axis=0)\n",
    "    max_daily_ridership = mean_ridership.max(axis=0)\n",
    "    min_daily_ridership = mean_ridership.min(axis=0)\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "\n",
    "min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2342.5999999999999, 3239.9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## np.dtype tells the type of each element in the array\n",
    "## 'int64' means 64 bit integer\n",
    "## each array is expected to have the same type of np.dtype\n",
    "## this means if you have strings and integers in your data\n",
    "## then you will be reading integers as strings or vice versa\n",
    "## this is a benefit of pandas dataframes\n",
    "## pandas dataframes assume each column is a different type of data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# DataFrame creation\n",
    "if False:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership_df.iloc[0]\n",
    "    print ridership_df.loc['05-05-11']\n",
    "    print ridership_df['R003']\n",
    "    print ridership_df.iloc[1, 3]\n",
    "    \n",
    "# Accessing multiple rows\n",
    "if False:\n",
    "    print ridership_df.iloc[1:4]\n",
    "    \n",
    "# Accessing multiple columns\n",
    "if False:\n",
    "    print ridership_df[['R003', 'R005']]\n",
    "    \n",
    "# Pandas axis\n",
    "if False:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df.sum()\n",
    "    print df.sum(axis=1)\n",
    "    print df.values.sum()\n",
    "    \n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    max_rider_first_day = ridership.iloc[0].argmax()\n",
    "    mean_for_max = ridership[max_rider_first_day].mean()\n",
    "    overall_mean = ridership.values.mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "mean_riders_for_max_station(ridership_df)\n",
    "\n",
    "## same answer as numpy's function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DataFrames are a great data structure to represent CSVs!\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.read_csv('nyc_subway_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>meanprecipi</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>meanwspdi</th>\n",
       "      <th>weather_lat</th>\n",
       "      <th>weather_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 16:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
       "0  R003  05-01-11  00:00:00   4388333  2911002                0   \n",
       "1  R003  05-01-11  04:00:00   4388333  2911002                0   \n",
       "2  R003  05-01-11  12:00:00   4388333  2911002                0   \n",
       "3  R003  05-01-11  16:00:00   4388333  2911002                0   \n",
       "4  R003  05-01-11  20:00:00   4388333  2911002                0   \n",
       "\n",
       "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
       "0              0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
       "1              0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
       "2              0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
       "3              0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
       "4              0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
       "\n",
       "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
       "0    0   55.9    3.5           0         30.258      55.98       7.86   \n",
       "1    0   52.0    3.5           0         30.258      55.98       7.86   \n",
       "2    0   62.1    6.9           0         30.258      55.98       7.86   \n",
       "3    0   57.9   15.0           0         30.258      55.98       7.86   \n",
       "4    0   52.0   10.4           0         30.258      55.98       7.86   \n",
       "\n",
       "   weather_lat  weather_lon  \n",
       "0    40.700348   -73.887177  \n",
       "1    40.700348   -73.887177  \n",
       "2    40.700348   -73.887177  \n",
       "3    40.700348   -73.887177  \n",
       "4    40.700348   -73.887177  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>fog</th>\n",
       "      <th>...</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>meanprecipi</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>meanwspdi</th>\n",
       "      <th>weather_lat</th>\n",
       "      <th>weather_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.264900e+04</td>\n",
       "      <td>4.264900e+04</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "      <td>42649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.812486e+07</td>\n",
       "      <td>1.986993e+07</td>\n",
       "      <td>1886.589955</td>\n",
       "      <td>1361.487866</td>\n",
       "      <td>10.046754</td>\n",
       "      <td>2.905719</td>\n",
       "      <td>0.714436</td>\n",
       "      <td>40.724647</td>\n",
       "      <td>-73.940364</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>...</td>\n",
       "      <td>29.971096</td>\n",
       "      <td>0.224741</td>\n",
       "      <td>63.103780</td>\n",
       "      <td>6.927872</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>29.971096</td>\n",
       "      <td>63.103780</td>\n",
       "      <td>6.927872</td>\n",
       "      <td>40.728555</td>\n",
       "      <td>-73.938693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.043607e+07</td>\n",
       "      <td>2.028986e+07</td>\n",
       "      <td>2952.385585</td>\n",
       "      <td>2183.845409</td>\n",
       "      <td>6.938928</td>\n",
       "      <td>2.079231</td>\n",
       "      <td>0.451688</td>\n",
       "      <td>0.071650</td>\n",
       "      <td>0.059713</td>\n",
       "      <td>0.098631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137942</td>\n",
       "      <td>0.417417</td>\n",
       "      <td>8.455597</td>\n",
       "      <td>4.510178</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.131158</td>\n",
       "      <td>6.939011</td>\n",
       "      <td>3.179832</td>\n",
       "      <td>0.065420</td>\n",
       "      <td>0.059582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.576152</td>\n",
       "      <td>-74.073622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.590000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.600204</td>\n",
       "      <td>-74.014870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.039762e+07</td>\n",
       "      <td>7.613712e+06</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.677107</td>\n",
       "      <td>-73.987342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.913333</td>\n",
       "      <td>58.283333</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>40.688591</td>\n",
       "      <td>-73.985130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.818389e+07</td>\n",
       "      <td>1.331609e+07</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.717241</td>\n",
       "      <td>-73.953459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.958000</td>\n",
       "      <td>60.950000</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>40.720570</td>\n",
       "      <td>-73.949150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>2.393771e+07</td>\n",
       "      <td>2255.000000</td>\n",
       "      <td>1537.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.759123</td>\n",
       "      <td>-73.907733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.060000</td>\n",
       "      <td>67.466667</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>40.755226</td>\n",
       "      <td>-73.912033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.357746e+08</td>\n",
       "      <td>1.493782e+08</td>\n",
       "      <td>32814.000000</td>\n",
       "      <td>34828.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.889185</td>\n",
       "      <td>-73.755383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.320000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>30.293333</td>\n",
       "      <td>79.800000</td>\n",
       "      <td>17.083333</td>\n",
       "      <td>40.862064</td>\n",
       "      <td>-73.694176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ENTRIESn        EXITSn  ENTRIESn_hourly  EXITSn_hourly  \\\n",
       "count  4.264900e+04  4.264900e+04     42649.000000   42649.000000   \n",
       "mean   2.812486e+07  1.986993e+07      1886.589955    1361.487866   \n",
       "std    3.043607e+07  2.028986e+07      2952.385585    2183.845409   \n",
       "min    0.000000e+00  0.000000e+00         0.000000       0.000000   \n",
       "25%    1.039762e+07  7.613712e+06       274.000000     237.000000   \n",
       "50%    1.818389e+07  1.331609e+07       905.000000     664.000000   \n",
       "75%    3.263049e+07  2.393771e+07      2255.000000    1537.000000   \n",
       "max    2.357746e+08  1.493782e+08     32814.000000   34828.000000   \n",
       "\n",
       "               hour      day_week       weekday      latitude     longitude  \\\n",
       "count  42649.000000  42649.000000  42649.000000  42649.000000  42649.000000   \n",
       "mean      10.046754      2.905719      0.714436     40.724647    -73.940364   \n",
       "std        6.938928      2.079231      0.451688      0.071650      0.059713   \n",
       "min        0.000000      0.000000      0.000000     40.576152    -74.073622   \n",
       "25%        4.000000      1.000000      0.000000     40.677107    -73.987342   \n",
       "50%       12.000000      3.000000      1.000000     40.717241    -73.953459   \n",
       "75%       16.000000      5.000000      1.000000     40.759123    -73.907733   \n",
       "max       20.000000      6.000000      1.000000     40.889185    -73.755383   \n",
       "\n",
       "                fog      ...          pressurei          rain         tempi  \\\n",
       "count  42649.000000      ...       42649.000000  42649.000000  42649.000000   \n",
       "mean       0.009824      ...          29.971096      0.224741     63.103780   \n",
       "std        0.098631      ...           0.137942      0.417417      8.455597   \n",
       "min        0.000000      ...          29.550000      0.000000     46.900000   \n",
       "25%        0.000000      ...          29.890000      0.000000     57.000000   \n",
       "50%        0.000000      ...          29.960000      0.000000     61.000000   \n",
       "75%        0.000000      ...          30.060000      0.000000     69.100000   \n",
       "max        1.000000      ...          30.320000      1.000000     86.000000   \n",
       "\n",
       "              wspdi   meanprecipi  meanpressurei     meantempi     meanwspdi  \\\n",
       "count  42649.000000  42649.000000   42649.000000  42649.000000  42649.000000   \n",
       "mean       6.927872      0.004618      29.971096     63.103780      6.927872   \n",
       "std        4.510178      0.016344       0.131158      6.939011      3.179832   \n",
       "min        0.000000      0.000000      29.590000     49.400000      0.000000   \n",
       "25%        4.600000      0.000000      29.913333     58.283333      4.816667   \n",
       "50%        6.900000      0.000000      29.958000     60.950000      6.166667   \n",
       "75%        9.200000      0.000000      30.060000     67.466667      8.850000   \n",
       "max       23.000000      0.157500      30.293333     79.800000     17.083333   \n",
       "\n",
       "        weather_lat   weather_lon  \n",
       "count  42649.000000  42649.000000  \n",
       "mean      40.728555    -73.938693  \n",
       "std        0.065420      0.059582  \n",
       "min       40.600204    -74.014870  \n",
       "25%       40.688591    -73.985130  \n",
       "50%       40.720570    -73.949150  \n",
       "75%       40.755226    -73.912033  \n",
       "max       40.862064    -73.694176  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0356485157722\n",
      "-0.0266933483216\n",
      "-0.229034323408\n",
      "0.585895470766\n"
     ]
    }
   ],
   "source": [
    "## Figuring out Pearson's R Exercise\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    # first you have to figure out the standard deviation \n",
    "    # of the uncorrected numbers - using ddof=0\n",
    "    std_x = (x - x.mean())/x.std(ddof=0)\n",
    "    std_y = (y-y.mean())/y.std(ddof=0)\n",
    "    # taking the average of the products than the mean of each variable\n",
    "    return (std_x * std_y).mean()\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print correlation(entries, rain)\n",
    "print correlation(entries, temp)\n",
    "print correlation(rain, temp)\n",
    "print correlation(entries, cum_entries)\n",
    "\n",
    "## it is possible to figure out Pearson's R with the formula corrcoef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dataframe Vectorized Operations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cumulative entries and exits for one station for a few hours\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2\n",
    "    \n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>214</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1        23       8\n",
       "2        18      18\n",
       "3        71      54\n",
       "4       170      44\n",
       "5       214      42\n",
       "6        87      11\n",
       "7        10       3\n",
       "8        36      89\n",
       "9       153     333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       F     F\n",
       "Barry       B     D\n",
       "Chris       C     F\n",
       "Dan         C     F\n",
       "Emilio      B     D\n",
       "Fred        C     F\n",
       "Greta       A     C\n",
       "Humbert     D     F\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Non-Built-In Functions for DataFrames\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print df.applymap(add_one)\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def convert_data_to_grade(data):\n",
    "    if data <= 59:\n",
    "        return \"F\"\n",
    "    elif data <= 69:\n",
    "        return \"D\"\n",
    "    elif data <= 79:\n",
    "        return \"C\"\n",
    "    elif data <= 89:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "        \n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return grades.applymap(convert_data_to_grade)\n",
    "\n",
    "convert_grades(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DataFrame apply()\n",
    "\n",
    "## apply() takes in a panda column and applies the function to a\n",
    "## new column. as seen above, but easier. apply() can also take an axis\n",
    "## argument, making it possible to use apply() on rows.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if False:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print convert_grades_curve(grades_df['exam1'])\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print grades_df.apply(convert_grades_curve)\n",
    "\n",
    "def standardize_column(column):\n",
    "    return (column - column.mean())/column.std(ddof=0)\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    return df.apply(standardize_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Andre     -2.315341\n",
       "Barry      0.220191\n",
       "Chris      0.020017\n",
       "Dan       -0.180156\n",
       "Emilio     0.753987\n",
       "Fred      -0.513779\n",
       "Greta      0.887436\n",
       "Humbert   -0.847401\n",
       "Ivan       1.354508\n",
       "James      0.620538\n",
       "Name: exam1, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_column(grades_df['exam1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>-2.315341</td>\n",
       "      <td>-2.304599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>0.220191</td>\n",
       "      <td>0.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.020017</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>-0.180156</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>0.753987</td>\n",
       "      <td>0.662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>-0.513779</td>\n",
       "      <td>-0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>0.887436</td>\n",
       "      <td>1.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>-0.847401</td>\n",
       "      <td>-0.786600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.354508</td>\n",
       "      <td>1.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0.620538</td>\n",
       "      <td>0.179400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exam1     exam2\n",
       "Andre   -2.315341 -2.304599\n",
       "Barry    0.220191  0.386400\n",
       "Chris    0.020017 -0.096600\n",
       "Dan     -0.180156 -0.096600\n",
       "Emilio   0.753987  0.662400\n",
       "Fred    -0.513779 -0.441600\n",
       "Greta    0.887436  1.490400\n",
       "Humbert -0.847401 -0.786600\n",
       "Ivan     1.354508  1.007400\n",
       "James    0.620538  0.179400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     4\n",
       "b    40\n",
       "c    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DataFrame.apply() Round 2!!!!\n",
    "\n",
    "## apply() can be used to apply a function to a whole row/column and\n",
    "## return a single value. apply() is super useful when you use functions\n",
    "## that aren't given (you create them).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if False:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max)\n",
    "\n",
    "def second_largest_in_column(column):\n",
    "    sorted_column = column.sort_values(ascending=False)\n",
    "    return sorted_column.iloc[1]\n",
    "    \n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return df.apply(second_largest_in_column)\n",
    "\n",
    "second_largest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DataFrame + Series = ?????\n",
    "## let's find out\n",
    "\n",
    "## Adding a DataFrame to a Series \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exam1     exam2\n",
      "Andre    0.707107 -0.707107\n",
      "Barry    0.707107 -0.707107\n",
      "Chris    0.707107 -0.707107\n",
      "Dan      0.707107 -0.707107\n",
      "Emilio   0.707107 -0.707107\n",
      "Fred     0.707107 -0.707107\n",
      "Greta    0.707107 -0.707107\n",
      "Humbert  0.707107 -0.707107\n",
      "Ivan     0.707107 -0.707107\n",
      "James    0.707107 -0.707107\n"
     ]
    }
   ],
   "source": [
    "## Adding/subtracting DataFrames & Series!!!!\n",
    "## use pandas fxns .add() .sub() .div() to make it easier to \n",
    "## combine dataframes and series.\n",
    "\n",
    "## IMPORTANT NOTE ABOUT STD()!!!!!!\n",
    "## By default, Numpy uses POPULATION Standard Deviation to calculate\n",
    "## std(), with \"ddof=0\". On the other hand, Pandas calculates SAMPLE\n",
    "## STANDARD DEVIATION, with \"ddof=1\". Only if we know all the scores,\n",
    "## then we can use \"ddof=0\"!!!!\n",
    "## VERY IMPORTANT!!!!!\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Adding using + (adds a series by axis='columns' by default)\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding with axis='index' (adds how a series should add to a DataFrame)\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "# Adding with axis='columns'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='columns')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    return (df - df.mean())/df.std(ddof=0)\n",
    "\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    mean_diffs = df.sub(df.mean(axis='columns'), axis='index')\n",
    "    return mean_diffs.div(df.std(axis='columns'), axis='index')\n",
    "\n",
    "print standardize_rows(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: ['a', 'b', 'e'], True: ['c', 'd', 'f', 'g']}\n"
     ]
    }
   ],
   "source": [
    "## Pandas groupby() fxn\n",
    "## Think of DataFrameGroupBy object as a dict mapping each account key \n",
    "## to a smaller DataFrame matching only that account key\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>meanprecipi</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>meanwspdi</th>\n",
       "      <th>weather_lat</th>\n",
       "      <th>weather_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 16:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-01 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
       "0  R003  05-01-11  00:00:00   4388333  2911002                0   \n",
       "1  R003  05-01-11  04:00:00   4388333  2911002                0   \n",
       "2  R003  05-01-11  12:00:00   4388333  2911002                0   \n",
       "3  R003  05-01-11  16:00:00   4388333  2911002                0   \n",
       "4  R003  05-01-11  20:00:00   4388333  2911002                0   \n",
       "\n",
       "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
       "0              0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
       "1              0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
       "2              0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
       "3              0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
       "4              0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
       "\n",
       "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
       "0    0   55.9    3.5           0         30.258      55.98       7.86   \n",
       "1    0   52.0    3.5           0         30.258      55.98       7.86   \n",
       "2    0   62.1    6.9           0         30.258      55.98       7.86   \n",
       "3    0   57.9   15.0           0         30.258      55.98       7.86   \n",
       "4    0   52.0   10.4           0         30.258      55.98       7.86   \n",
       "\n",
       "   weather_lat  weather_lon  \n",
       "0    40.700348   -73.887177  \n",
       "1    40.700348   -73.887177  \n",
       "2    40.700348   -73.887177  \n",
       "3    40.700348   -73.887177  \n",
       "4    40.700348   -73.887177  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "\n",
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridership_by_day = subway_df.groupby('day_week').mean()['ENTRIESn_hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10ebefbd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAERCAYAAACXT3dwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ebef290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "ridership_by_day.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Using groupby() to Calculate Hourly Entries and Exits\n",
    "\n",
    "In the quiz where you calculated hourly entries and exits, you \n",
    "did so for a single set of cumulative entries. However, in the \n",
    "original data, there was a separate set of numbers for each \n",
    "station.\n",
    "\n",
    "Thus, to correctly calculate the hourly entries and exits, it \n",
    "was necessary to group by station and day, then calculate the \n",
    "hourly entries and exits within each day.\n",
    "\n",
    "Write a function to do that. You should use the apply() \n",
    "function to call the function you wrote previously. You should \n",
    "also make sure you restrict your grouped data to just the \n",
    "entries and exits columns, since your function may cause an \n",
    "error if it is called on non-numerical data types.\n",
    "\n",
    "If you would like to learn more about using groupby() in Pandas,\n",
    "this page contains more details.\n",
    "\n",
    "Note: You will not be able to reproduce the ENTRIESn_hourly \n",
    "and EXITSn_hourly columns in the full dataset using this method.\n",
    "When creating the dataset, we did extra processing to \n",
    "remove erroneous values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1       NaN     NaN\n",
       "2        23       8\n",
       "3        14       8\n",
       "4        18      18\n",
       "5        29     205\n",
       "6        71      54\n",
       "7       132     593\n",
       "8       170      44"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if False:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(standardize)\n",
    "    \n",
    "# Find second largest value in each group\n",
    "if False:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(second_largest)\n",
    "\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "'''Take a DataFrame with cumulative entries\n",
    "and exits and return a DataFrame with hourly entries and exits.\n",
    "The hourly entries and exits should be calculated separately for\n",
    "each station (the 'UNIT' column).'''\n",
    "\n",
    "\n",
    "def hourly_for_group(entries_and_exits):\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "\n",
    "ridership_df.groupby('UNIT')[['ENTRIESn', 'EXITSn']].apply(hourly_for_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Combining Pandas DataFrame - merge()\n",
    "\n",
    "## merge() allows the tables to be joined together\n",
    "## how='left' determines what happens if some account keys are present\n",
    "## in one table but not another\n",
    "## how='right', how='inner', & how='outer' are the other options for how field\n",
    "## how='inner' allows only rows in both tables to be included in merge\n",
    "## how='right' would have included the rows present in the right table, but not in the left\n",
    "## how='outer' would have included both tables\n",
    "## on = '' tells the merge() function what shared columns are in both DataFrames\n",
    "## if columns don't have the same name, but the same value \n",
    "## (such as left DataFrame having 'DATEn' and right DataFrame having 'date') \n",
    "## there is a field called left_on = '' and right_on='' where you can\n",
    "## specify what the different columns are named that should be merged together\n",
    "\n",
    "## see example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    # alternately, you could also provide the following code to write merge()\n",
    "    # subway_df.merge(weather_df, on=['DATEn', 'hour', 'latitude', 'longitude'], how='inner')\n",
    "    return pd.merge(left=subway_df, right=weather_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>4388348</td>\n",
       "      <td>2911036</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>4389885</td>\n",
       "      <td>2912127</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  ENTRIESn   EXITSn  UNIT  hour   latitude  longitude\n",
       "0  05-01-11   4388333  2911002  R003     0  40.689945 -73.872564\n",
       "1  05-02-11   4388348  2911036  R003     0  40.689945 -73.872564\n",
       "2  05-03-11   4389885  2912127  R003     0  40.689945 -73.872564"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>fog</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  fog  hour   latitude  longitude  pressurei  rain  tempi  wspdi\n",
       "0  05-01-11    0     0  40.689945 -73.872564      30.24     0   52.0    8.1\n",
       "1  05-01-11    0     0  40.691320 -73.867135      30.24     0   52.0    8.1\n",
       "2  05-02-11    0     0  40.689945 -73.872564      30.32     0   48.9    6.9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude  fog  \\\n",
      "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564    0   \n",
      "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564    0   \n",
      "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564    0   \n",
      "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564    0   \n",
      "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564    0   \n",
      "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135    0   \n",
      "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135    0   \n",
      "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135    0   \n",
      "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135    0   \n",
      "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135    0   \n",
      "\n",
      "   pressurei  rain  tempi  wspdi  \n",
      "0      30.24     0   52.0    8.1  \n",
      "1      30.32     0   48.9    6.9  \n",
      "2      30.14     0   54.0    3.5  \n",
      "3      29.98     0   57.2   15.0  \n",
      "4      30.01     0   48.9   15.0  \n",
      "5      30.24     0   52.0    8.1  \n",
      "6      30.32     0   48.9    6.9  \n",
      "7      30.14     0   54.0    3.5  \n",
      "8      29.98     0   57.2   15.0  \n",
      "9      30.01     0   48.9   15.0  \n"
     ]
    }
   ],
   "source": [
    "print combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      above_three  value\n",
      "even                    \n",
      "False       False      1\n",
      "True        False      2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'even'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8d5f71756d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfirst_even\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'even'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfirst_even\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mfirst_even\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'even'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Causes an error. 'even' is no longer a column in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# groupby() with as_index=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'even'"
     ]
    }
   ],
   "source": [
    "## Creating plots for DataFrames\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# groupby() without as_index\n",
    "if False:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print first_even\n",
    "    print first_even['even'] # Causes an error. 'even' is no longer a column in the DataFrame\n",
    "    \n",
    "# groupby() with as_index=False\n",
    "if False:\n",
    "    print example_df.groupby('even', as_index=False).first()\n",
    "    print example_df['even'] # Now 'even' is still a column in the DataFrame\n",
    "\n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3D data\n",
    "\n",
    "'''\n",
    "Now that you've worked with one-dimensional and two-dimensional \n",
    "data, you might be wondering how to work with three or more dimensions.\n",
    "\n",
    "3D data in NumPy\n",
    "\n",
    "NumPy arrays can have arbitrarily many dimensions. Just like \n",
    "you can create a 1D array from a list, and a 2D array from a list \n",
    "of lists, you can create a 3D array from a list of lists of lists, \n",
    "and so on. For example, the following code would create a 3D array:\n",
    "\n",
    "a = np.array([\n",
    "    [['A1a', 'A1b', A1c'], ['A2a', 'A2b', 'A2c']],\n",
    "    [['B1a', 'B1b', 'B1c'], ['B2a', 'B2b', 'B2c']]\n",
    "])\n",
    "3D data in Pandas\n",
    "\n",
    "Pandas has a data structure called a Panel, which is similar to \n",
    "a DataFrame or a Series, but for 3D data. If you would like,\n",
    "you can learn more about Panels here.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
